{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6accc72-8f48-4e4b-b2da-46c3a9693e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import socket\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d3dcbf-1652-4a06-9d24-8b6b5b7593f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioArXiV_MVP:\n",
    "    def __init__(self, \n",
    "                 i_start:int=0, \n",
    "                 i_delta:int=8000, \n",
    "                 crawl_delay:int=7.0):\n",
    "        '''\n",
    "        Init\n",
    "        '''\n",
    "        # store path\n",
    "        if 'lambda' in socket.gethostname():\n",
    "            self.download_dir = Path('/homes/csiebenschuh/Projects/dataprep/data/bioarxiv')\n",
    "        else:\n",
    "            self.download_dir = Path('/home/siebenschuh/Projects/dataprep/data/bioarxiv') # Polaris\n",
    "        assert self.download_dir.is_dir(), f\"Initializing `ArXiV_MVP` failed as {self.download_dir} does not exist\"\n",
    "\n",
    "        self.crawl_delay = crawl_delay\n",
    "        df = pd.read_csv('./registry/biorxiv_database.csv', sep='|')\n",
    "        \n",
    "        # subset\n",
    "        df_sub = df.iloc[i_start:i_start+i_delta]\n",
    "        self.df_sub = df_sub.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def get_arxiv_articles_with_html(self,):\n",
    "        '''\n",
    "        Attempt to download PDFs and HTML files\n",
    "        '''\n",
    "\n",
    "        # setup directories if needed\n",
    "        download_dir = Path(self.download_dir)\n",
    "        pdf_path = download_dir / 'pdf'\n",
    "        html_path = download_dir / 'html'\n",
    "        csv_path = download_dir / 'csv'\n",
    "\n",
    "        assert download_dir.is_dir(), \"`download_dir` invalid directory path\"\n",
    "\n",
    "         # driver options \n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "\n",
    "        # loop entries\n",
    "        for _,row in self.df_sub.iterrows():\n",
    "            doi = row['doi']\n",
    "            file_stem = doi.replace('/', '_')\n",
    "\n",
    "            # HTML / PDF\n",
    "            html_url = 'https://www.biorxiv.org/content/' + row['doi'] + '.full'\n",
    "            pdf_url = 'https://www.biorxiv.org/content/' + row['doi'] + '.full.pdf'\n",
    "\n",
    "            # Check if HTML URL exists\n",
    "            #print(html_url)\n",
    "\n",
    "            # HTML\n",
    "            driver.get(html_url)\n",
    "            html_content = driver.page_source\n",
    "\n",
    "            # wait\n",
    "            time.sleep(self.crawl_delay)\n",
    "            \n",
    "            # PDF\n",
    "            pdf_response = requests.get(pdf_url)\n",
    "            if pdf_response.status_code == 200:\n",
    "                # Save HTML content to file\n",
    "                with open(str(html_path / (file_stem + '.html')), 'w', encoding='utf-8') as file:\n",
    "                    file.write(html_content)\n",
    "\n",
    "                # Save PDF content to file\n",
    "                with open(f\"{pdf_path}/{file_stem}.pdf\", 'wb') as pdf_file:\n",
    "                    pdf_file.write(pdf_response.content)\n",
    "\n",
    "                # Meta \n",
    "                row.to_csv(f\"{csv_path}/{file_stem}.csv\", sep='|')\n",
    "\n",
    "                # wait again\n",
    "                time.sleep(self.crawl_delay)\n",
    "                \n",
    "            else:\n",
    "                print(f'nothing written, {pdf_response.status_code}')\n",
    "\n",
    "        if _ > 5:\n",
    "            return None\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe65e1d-aae5-4bb4-8d9e-5c9218393007",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = BioArXiV_MVP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b0d1a2-0d14-4c47-af54-f10712ebef1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m html_content \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_arxiv_articles_with_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m, in \u001b[0;36mBioArXiV_MVP.get_arxiv_articles_with_html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m     row\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_stem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# wait again\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrawl_delay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnothing written, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_response\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "html_content = b.get_arxiv_articles_with_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52f57d-c0c7-4bd1-af18-93762462318e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
