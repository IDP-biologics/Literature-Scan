{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c2df0b-261f-4e2a-95cc-6acfc8ced399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import socket\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7254f122-4b27-4efd-842d-430bb6d687a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDPI_MVP:\n",
    "    def __init__(self, \n",
    "                 i_start:int=0, \n",
    "                 i_delta:int=8000, \n",
    "                 crawl_delay:int=8.0):\n",
    "        '''\n",
    "        Init\n",
    "        '''\n",
    "        # store path\n",
    "        if 'lambda' in socket.gethostname():\n",
    "            self.download_dir = Path('/homes/csiebenschuh/Projects/dataprep/data/mdpi')\n",
    "        else:\n",
    "            self.download_dir = Path('/eagle/projects/argonne_tpc/siebenschuh/aurora_gpt/raw_data/mdpi') # Polaris\n",
    "        assert self.download_dir.is_dir(), f\"Initializing `ArXiV_MVP` failed as {self.download_dir} does not exist\"\n",
    "\n",
    "        self.crawl_delay = crawl_delay\n",
    "        df = pd.read_csv('./registry/mdpi_database.csv', sep='|')\n",
    "        \n",
    "        # subset\n",
    "        df_sub = df.iloc[i_start:i_start+i_delta]\n",
    "        self.df_sub = df_sub.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        # shuffle order\n",
    "        self.df_sub = self.df_sub.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    def get_arxiv_articles_with_html(self,):\n",
    "        '''\n",
    "        Attempt to download PDFs and HTML files\n",
    "        '''\n",
    "\n",
    "        # setup directories if needed\n",
    "        download_dir = Path(self.download_dir)\n",
    "        pdf_path = download_dir / 'pdf'\n",
    "        html_path = download_dir / 'html'\n",
    "        csv_path = download_dir / 'csv'\n",
    "\n",
    "        assert download_dir.is_dir(), \"`download_dir` invalid directory path\"\n",
    "\n",
    "         # driver options \n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "\n",
    "        # loop entries\n",
    "        for _,row in self.df_sub.iterrows():\n",
    "            doi = str(row['html_url']).split('www.mdpi.com/')[-1].replace('/', '.')  # df['html_url'][0].split('www.mdpi.com/')[-1].replace('/', '.')\n",
    "            file_stem = doi.replace('/', '_')\n",
    "\n",
    "            # HTML / PDF\n",
    "            html_url = row['html_url']\n",
    "            pdf_url = row['pdf_url']\n",
    "\n",
    "            # HTML\n",
    "            driver.get(html_url)\n",
    "            html_content = driver.page_source\n",
    "\n",
    "            # wait\n",
    "            time.sleep(self.crawl_delay)\n",
    "            \n",
    "            # PDF\n",
    "            pdf_response = requests.get(pdf_url)\n",
    "            if pdf_response.status_code == 200:\n",
    "                # Save HTML content to file\n",
    "                with open(str(html_path / (file_stem + '.html')), 'w', encoding='utf-8') as file:\n",
    "                    file.write(html_content)\n",
    "\n",
    "                # Save PDF content to file\n",
    "                with open(f\"{pdf_path}/{file_stem}.pdf\", 'wb') as pdf_file:\n",
    "                    pdf_file.write(pdf_response.content)\n",
    "\n",
    "                # Meta \n",
    "                row.to_csv(f\"{csv_path}/{file_stem}.csv\", sep='|')\n",
    "\n",
    "                # wait again\n",
    "                time.sleep(random.uniform(0.2, 1.5))\n",
    "                \n",
    "            else:\n",
    "                print(f'nothing written, {pdf_response.status_code}')\n",
    "        \n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e1ddb14-fe75-46e1-a2b9-9753a9e5e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MDPI_MVP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464c8b87-9eba-43b4-923c-32b1f5061012",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_arxiv_articles_with_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cecc6a-8060-4f5b-b733-4885ecfaa9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
